# ğŸ¢ Sistema ERP de Big Data - Arquitectura de Recomendaciones Comerciales

## ğŸ“ Estructura del Proyecto

```
Practica 4/
â”œâ”€â”€ ğŸ“Š dashboards/          # Dashboards de visualizaciÃ³n (Streamlit)
â”‚   â”œâ”€â”€ erp_dashboard.py                    # Dashboard estÃ¡tico (datos histÃ³ricos)
â”‚   â”œâ”€â”€ erp_dashboard_dinamico.py           # Dashboard dinÃ¡mico (tiempo real)
â”‚   â””â”€â”€ print_recommendations_consumer.py   # Dashboard de recomendaciones ML
â”‚
â”œâ”€â”€ ğŸ”„ services/            # Servicios de mensajerÃ­a (Kafka/MongoDB)
â”‚   â”œâ”€â”€ erp_simulator_producer.py   # Productor Kafka (envÃ­a datos a Kafka)
â”‚   â”œâ”€â”€ erp_kafka_to_mongo.py       # Consumidor Kafka â†’ MongoDB
â”‚   â””â”€â”€ reco_service_stream.py      # Servicio de recomendaciones en tiempo real
â”‚
â”œâ”€â”€ ğŸ”§ scripts/             # Scripts de una sola ejecuciÃ³n
â”‚   â”œâ”€â”€ process_superstore_csv.py           # Procesa CSV real â†’ CSV normalizados
â”‚   â”œâ”€â”€ model_train_reco.py                 # Entrena modelo de ML
â”‚   â””â”€â”€ mongo_data_processor_completo.py    # Procesa datos para dashboards estÃ¡ticos
â”‚
â”œâ”€â”€ âš™ï¸ config/              # ConfiguraciÃ³n e infraestructura
â”‚   â”œâ”€â”€ config.py              # ConfiguraciÃ³n centralizada (MongoDB, Kafka)
â”‚   â”œâ”€â”€ docker-compose.yml     # Servicios Docker (Kafka, MongoDB, etc.)
â”‚   â””â”€â”€ requirements.txt       # Dependencias Python
â”‚
â”œâ”€â”€ ğŸ“š docs/                # DocumentaciÃ³n
â”‚   â”œâ”€â”€ README.md                              # DocumentaciÃ³n principal
â”‚   â”œâ”€â”€ ARQUITECTURA.md                        # Arquitectura del sistema
â”‚   â”œâ”€â”€ MIGRACION_DATOS_REALES.md             # MigraciÃ³n a datos reales
â”‚   â””â”€â”€ EXPLICACION_MODELO_RECOMENDACIONES.md # ExplicaciÃ³n del modelo ML
â”‚
â””â”€â”€ ğŸ’¾ data/                # Datos y modelos
    â”œâ”€â”€ archive/            # Datos fuente originales
    â”‚   â””â”€â”€ Sample - Superstore.csv
    â”œâ”€â”€ csv_out/            # CSVs procesados (listos para Kafka)
    â”‚   â”œâ”€â”€ products.csv
    â”‚   â”œâ”€â”€ customers.csv
    â”‚   â”œâ”€â”€ sales.csv
    â”‚   â””â”€â”€ sales_items.csv
    â””â”€â”€ models/             # Modelos entrenados
        â””â”€â”€ item_sim.pkl    # Modelo de similitud item-item
```

## ğŸš€ Inicio RÃ¡pido

### 1. Instalar Dependencias
```bash
pip install -r config/requirements.txt
```

### 2. Iniciar Infraestructura
```bash
cd config
docker-compose up -d
```

### 3. Procesar Datos (Una vez)
```bash
python scripts/process_superstore_csv.py
```

### 4. Entrenar Modelo (Una vez)
```bash
python scripts/model_train_reco.py
```

### 5. Ejecutar Pipeline de Datos
```bash
# Terminal 1: Productor Kafka
python services/erp_simulator_producer.py

# Terminal 2: Consumidor Kafka â†’ MongoDB
python services/erp_kafka_to_mongo.py

# Terminal 3: Procesador de datos (opcional, para dashboards estÃ¡ticos)
python scripts/mongo_data_processor_completo.py

# Terminal 4: Servicio de recomendaciones
python services/reco_service_stream.py
```

### 6. Ejecutar Dashboards
```bash
# Terminal 5: Dashboard EstÃ¡tico (Puerto 8501)
streamlit run dashboards/erp_dashboard.py --server.port 8501

# Terminal 6: Dashboard DinÃ¡mico (Puerto 8502)
streamlit run dashboards/erp_dashboard_dinamico.py --server.port 8502

# Terminal 7: Dashboard de Recomendaciones
streamlit run dashboards/print_recommendations_consumer.py
```

## ğŸ“– DocumentaciÃ³n Completa

Ver la documentaciÃ³n completa en la carpeta `docs/`:
- `docs/README.md` - DocumentaciÃ³n principal del sistema
- `docs/ARQUITECTURA.md` - Arquitectura detallada
- `docs/EXPLICACION_MODELO_RECOMENDACIONES.md` - ExplicaciÃ³n del modelo ML

## ğŸ”§ ConfiguraciÃ³n

Edita `config/config.py` con tus credenciales de MongoDB Atlas.

## ğŸ“Š Componentes Principales

### Dashboards (`dashboards/`)
- **erp_dashboard.py**: AnÃ¡lisis histÃ³rico de ventas
- **erp_dashboard_dinamico.py**: Monitoreo en tiempo real
- **print_recommendations_consumer.py**: VisualizaciÃ³n de recomendaciones ML

### Servicios (`services/`)
- **erp_simulator_producer.py**: EnvÃ­a datos CSV a Kafka
- **erp_kafka_to_mongo.py**: Consume Kafka y guarda en MongoDB
- **reco_service_stream.py**: Genera recomendaciones en tiempo real

### Scripts (`scripts/`)
- **process_superstore_csv.py**: Procesa datos reales del CSV
- **model_train_reco.py**: Entrena modelo de recomendaciones
- **mongo_data_processor_completo.py**: Crea agregaciones para dashboards

---

**Sistema ERP de Big Data - Arquitectura de Recomendaciones Comerciales** ğŸ¢ğŸ“Š

